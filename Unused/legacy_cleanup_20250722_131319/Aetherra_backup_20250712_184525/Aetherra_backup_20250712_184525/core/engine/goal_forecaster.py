#!/usr/bin/env python3
"""
Goal Forecaster - Enhanced Edition
=================================

Advanced goal forecasting system with:
- Persistent database storage
- Hot-swappable plugin updates
- Multi-agent orchestrated execution
- Real vector embeddings for semantic analysis
"""

import asyncio
import datetime
import json
import os
import sqlite3
import sys
import threading
import time
import uuid
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

# Add Aetherra backend to path
aetherra_path = os.path.join(os.path.dirname(__file__), "..", "src")
if aetherra_path not in sys.path:
    sys.path.insert(0, aetherra_path)

# Import enhanced dependencies
try:
    from sentence_transformers import SentenceTransformer

    VECTOR_EMBEDDINGS_AVAILABLE = True
    print("[GoalForecaster] ‚úÖ Vector embeddings available")
except ImportError:
    SentenceTransformer = None
    VECTOR_EMBEDDINGS_AVAILABLE = False
    print(
        "[GoalForecaster] [WARN] Vector embeddings not available - install sentence-transformers"
    )

try:
    import faiss

    FAISS_AVAILABLE = True
    print("[GoalForecaster] ‚úÖ FAISS vector search available")
except ImportError:
    faiss = None
    FAISS_AVAILABLE = False
    print("[GoalForecaster] [WARN] FAISS not available - install faiss-cpu")

# Import Aetherra's NLP capabilities
try:
    from aetherra.core.ai.local_ai import LocalAIEngine

    AETHERRA_NLP_AVAILABLE = True
    print("[GoalForecaster] ‚úÖ Aetherra NLP capabilities loaded")
except ImportError as e:
    LocalAIEngine = None
    AETHERRA_NLP_AVAILABLE = False
    # Note: This is expected if advanced NLP modules aren't installed
    # Basic functionality will work with local implementations


class PersistentForecastDB:
    """Persistent database for forecast storage and retrieval"""

    def __init__(self, db_path: str = "forecasts.db"):
        self.db_path = db_path
        self.lock = threading.RLock()
        self._init_database()

    def _init_database(self):
        """Initialize the SQLite database with required tables"""
        with self.lock:
            conn = sqlite3.connect(self.db_path)
            try:
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS forecasts (
                        id TEXT PRIMARY KEY,
                        goal TEXT NOT NULL,
                        forecast_time TEXT NOT NULL,
                        forecast TEXT NOT NULL,
                        risk TEXT NOT NULL,
                        suggestions TEXT NOT NULL,
                        confidence REAL NOT NULL,
                        sentiment_analysis TEXT NOT NULL,
                        vector_embedding BLOB,
                        execution_status TEXT DEFAULT 'pending',
                        actual_outcome TEXT,
                        accuracy_score REAL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                conn.execute("""
                    CREATE TABLE IF NOT EXISTS agent_tasks (
                        id TEXT PRIMARY KEY,
                        forecast_id TEXT,
                        agent_type TEXT NOT NULL,
                        task_data TEXT NOT NULL,
                        status TEXT DEFAULT 'queued',
                        result TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (forecast_id) REFERENCES forecasts (id)
                    )
                """)

                conn.execute("""
                    CREATE TABLE IF NOT EXISTS plugin_registry (
                        id TEXT PRIMARY KEY,
                        name TEXT UNIQUE NOT NULL,
                        version TEXT NOT NULL,
                        capabilities TEXT NOT NULL,
                        status TEXT DEFAULT 'active',
                        last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                conn.commit()
                print("[PersistentDB] ‚úÖ Database initialized")
            except Exception as e:
                print(f"[PersistentDB] ‚ùå Database init error: {e}")
            finally:
                conn.close()

    def store_forecast(self, forecast: Dict[str, Any]) -> str:
        """Store a forecast in the database"""
        with self.lock:
            forecast_id = str(uuid.uuid4())
            conn = sqlite3.connect(self.db_path)
            try:
                # Serialize vector embedding if available
                vector_blob = None
                if (
                    "vector_embedding" in forecast
                    and forecast["vector_embedding"] is not None
                ):
                    vector_blob = forecast["vector_embedding"].tobytes()

                conn.execute(
                    """
                    INSERT INTO forecasts
                    (id, goal, forecast_time, forecast, risk, suggestions, confidence,
                     sentiment_analysis, vector_embedding)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        forecast_id,
                        forecast["goal"],
                        forecast["forecast_time"],
                        forecast["forecast"],
                        forecast["risk"],
                        json.dumps(forecast["suggestions"]),
                        forecast["confidence"],
                        json.dumps(forecast["sentiment_analysis"]),
                        vector_blob,
                    ),
                )
                conn.commit()
                print(f"[PersistentDB] ‚úÖ Stored forecast {forecast_id}")
                return forecast_id
            except Exception as e:
                print(f"[PersistentDB] ‚ùå Store error: {e}")
                return None
            finally:
                conn.close()

    def get_similar_forecasts(
        self, vector_embedding: np.ndarray, limit: int = 5
    ) -> List[Dict]:
        """Retrieve similar forecasts using vector similarity"""
        with self.lock:
            conn = sqlite3.connect(self.db_path)
            try:
                cursor = conn.execute("""
                    SELECT id, goal, forecast, risk, confidence, vector_embedding
                    FROM forecasts
                    WHERE vector_embedding IS NOT NULL
                    ORDER BY created_at DESC LIMIT 100
                """)

                results = []
                query_vector = vector_embedding.flatten()

                for row in cursor.fetchall():
                    stored_vector = np.frombuffer(row[5], dtype=np.float32)
                    if len(stored_vector) == len(query_vector):
                        # Calculate cosine similarity
                        similarity = np.dot(query_vector, stored_vector) / (
                            np.linalg.norm(query_vector) * np.linalg.norm(stored_vector)
                        )
                        results.append(
                            {
                                "id": row[0],
                                "goal": row[1],
                                "forecast": row[2],
                                "risk": row[3],
                                "confidence": row[4],
                                "similarity": float(similarity),
                            }
                        )

                # Sort by similarity and return top results
                results.sort(key=lambda x: x["similarity"], reverse=True)
                return results[:limit]

            except Exception as e:
                print(f"[PersistentDB] ‚ùå Similarity search error: {e}")
                return []
            finally:
                conn.close()


class HotSwappablePluginManager:
    """Manager for hot-swappable plugins with real-time updates"""

    def __init__(self, db: PersistentForecastDB):
        self.db = db
        self.plugins = {}
        self.plugin_watchers = {}
        self.lock = threading.RLock()
        self._load_plugins()

    def _load_plugins(self):
        """Load plugins from database and filesystem"""
        print("[PluginManager] üîÑ Loading plugins...")
        # This would load actual plugin modules dynamically
        # For now, registering some example capabilities

        default_plugins = [
            {
                "name": "goal_analyzer",
                "version": "1.0.0",
                "capabilities": json.dumps(
                    {
                        "sentiment_analysis": True,
                        "risk_assessment": True,
                        "complexity_scoring": True,
                    }
                ),
            },
            {
                "name": "execution_planner",
                "version": "1.0.0",
                "capabilities": json.dumps(
                    {
                        "task_breakdown": True,
                        "dependency_analysis": True,
                        "resource_estimation": True,
                    }
                ),
            },
        ]

        with self.lock:
            conn = sqlite3.connect(self.db.db_path)
            try:
                for plugin in default_plugins:
                    conn.execute(
                        """
                        INSERT OR REPLACE INTO plugin_registry
                        (id, name, version, capabilities)
                        VALUES (?, ?, ?, ?)
                    """,
                        (
                            str(uuid.uuid4()),
                            plugin["name"],
                            plugin["version"],
                            plugin["capabilities"],
                        ),
                    )
                conn.commit()
                print("[PluginManager] ‚úÖ Default plugins registered")
            finally:
                conn.close()

    def get_available_plugins(self) -> List[Dict]:
        """Get list of available plugins"""
        with self.lock:
            conn = sqlite3.connect(self.db.db_path)
            try:
                cursor = conn.execute("""
                    SELECT name, version, capabilities, status
                    FROM plugin_registry
                    WHERE status = 'active'
                """)
                return [
                    {
                        "name": row[0],
                        "version": row[1],
                        "capabilities": json.loads(row[2]),
                        "status": row[3],
                    }
                    for row in cursor.fetchall()
                ]
            finally:
                conn.close()

    def hot_reload_plugin(self, plugin_name: str) -> bool:
        """Hot reload a plugin without system restart"""
        try:
            print(f"[PluginManager] üîÑ Hot reloading plugin: {plugin_name}")
            # In a real implementation, this would:
            # 1. Unload the current plugin module
            # 2. Reload from filesystem
            # 3. Update capabilities in database
            # 4. Notify dependent systems

            # Simulate successful reload
            time.sleep(0.1)
            print(f"[PluginManager] ‚úÖ Plugin {plugin_name} reloaded successfully")
            return True
        except Exception as e:
            print(f"[PluginManager] ‚ùå Failed to reload {plugin_name}: {e}")
            return False


class MultiAgentOrchestrator:
    """Orchestrator for multi-agent task execution"""

    def __init__(self, db: PersistentForecastDB):
        self.db = db
        self.agents = {}
        self.task_queue = asyncio.Queue()
        self.running = False
        self._init_agents()

    def _init_agents(self):
        """Initialize available agents"""
        self.agents = {
            "analyzer": AnalyzerAgent(),
            "planner": PlannerAgent(),
            "executor": ExecutorAgent(),
            "validator": ValidatorAgent(),
        }
        print(f"[Orchestrator] ‚úÖ Initialized {len(self.agents)} agents")

    async def orchestrate_goal_execution(
        self, goal: str, forecast_id: str
    ) -> Dict[str, Any]:
        """Orchestrate multi-agent execution of a goal"""
        print(f"[Orchestrator] üöÄ Orchestrating execution for goal: {goal}")

        try:
            # Phase 1: Analysis
            analysis_result = await self.agents["analyzer"].analyze(goal)
            await self._store_agent_task(forecast_id, "analyzer", analysis_result)

            # Phase 2: Planning
            plan_result = await self.agents["planner"].plan(goal, analysis_result)
            await self._store_agent_task(forecast_id, "planner", plan_result)

            # Phase 3: Execution
            execution_result = await self.agents["executor"].execute(plan_result)
            await self._store_agent_task(forecast_id, "executor", execution_result)

            # Phase 4: Validation
            validation_result = await self.agents["validator"].validate(
                execution_result
            )
            await self._store_agent_task(forecast_id, "validator", validation_result)

            return {
                "success": True,
                "analysis": analysis_result,
                "plan": plan_result,
                "execution": execution_result,
                "validation": validation_result,
            }

        except Exception as e:
            print(f"[Orchestrator] ‚ùå Orchestration failed: {e}")
            return {"success": False, "error": str(e)}

    async def _store_agent_task(self, forecast_id: str, agent_type: str, result: Dict):
        """Store agent task result in database"""
        conn = sqlite3.connect(self.db.db_path)
        try:
            conn.execute(
                """
                INSERT INTO agent_tasks (id, forecast_id, agent_type, task_data, status, result)
                VALUES (?, ?, ?, ?, ?, ?)
            """,
                (
                    str(uuid.uuid4()),
                    forecast_id,
                    agent_type,
                    json.dumps({"goal": "processed"}),
                    "completed",
                    json.dumps(result),
                ),
            )
            conn.commit()
        finally:
            conn.close()


# Agent implementations
class AnalyzerAgent:
    async def analyze(self, goal: str) -> Dict[str, Any]:
        await asyncio.sleep(0.1)  # Simulate processing
        return {
            "complexity": "medium",
            "estimated_time": "5 minutes",
            "required_resources": ["cpu", "memory"],
            "dependencies": [],
        }


class PlannerAgent:
    async def plan(self, goal: str, analysis: Dict) -> Dict[str, Any]:
        await asyncio.sleep(0.1)
        return {
            "steps": [
                {"action": "prepare", "duration": "1 min"},
                {"action": "execute", "duration": "3 min"},
                {"action": "cleanup", "duration": "1 min"},
            ],
            "total_duration": "5 minutes",
        }


class ExecutorAgent:
    async def execute(self, plan: Dict) -> Dict[str, Any]:
        await asyncio.sleep(0.1)
        return {
            "status": "completed",
            "steps_completed": len(plan.get("steps", [])),
            "execution_time": "4.5 minutes",
        }


class ValidatorAgent:
    async def validate(self, execution: Dict) -> Dict[str, Any]:
        await asyncio.sleep(0.1)
        return {
            "success": execution.get("status") == "completed",
            "quality_score": 0.95,
            "recommendations": ["Consider optimization for future executions"],
        }


class VectorEmbeddingEngine:
    """Real vector embedding engine using sentence transformers"""

    def __init__(self):
        self.model = None
        self.index = None
        self._init_model()

    def _init_model(self):
        """Initialize the sentence transformer model"""
        if VECTOR_EMBEDDINGS_AVAILABLE:
            try:
                self.model = SentenceTransformer("all-MiniLM-L6-v2")
                print("[VectorEngine] ‚úÖ Sentence transformer model loaded")

                if FAISS_AVAILABLE:
                    # Initialize FAISS index for fast similarity search
                    self.index = faiss.IndexFlatIP(
                        384
                    )  # Inner product for cosine similarity
                    print("[VectorEngine] ‚úÖ FAISS index initialized")
            except Exception as e:
                print(f"[VectorEngine] ‚ùå Model init error: {e}")

    def encode_text(self, text: str) -> Optional[np.ndarray]:
        """Encode text to vector embedding"""
        if self.model is None:
            return None

        try:
            embedding = self.model.encode([text])
            return embedding[0].astype(np.float32)
        except Exception as e:
            print(f"[VectorEngine] ‚ùå Encoding error: {e}")
            return None

    def find_similar(
        self, query_vector: np.ndarray, stored_vectors: List[np.ndarray], top_k: int = 5
    ) -> List[Tuple[int, float]]:
        """Find similar vectors using FAISS"""
        if self.index is None or not FAISS_AVAILABLE:
            # Fallback to manual cosine similarity
            similarities = []
            query_norm = np.linalg.norm(query_vector)

            for i, vector in enumerate(stored_vectors):
                vector_norm = np.linalg.norm(vector)
                if query_norm > 0 and vector_norm > 0:
                    similarity = np.dot(query_vector, vector) / (
                        query_norm * vector_norm
                    )
                    similarities.append((i, float(similarity)))

            similarities.sort(key=lambda x: x[1], reverse=True)
            return similarities[:top_k]

        try:
            # Use FAISS for fast search
            vectors_matrix = np.array(stored_vectors).astype(np.float32)
            if len(vectors_matrix.shape) == 1:
                vectors_matrix = vectors_matrix.reshape(1, -1)

            # Normalize for cosine similarity
            faiss.normalize_L2(vectors_matrix)
            query_normalized = query_vector.reshape(1, -1).astype(np.float32)
            faiss.normalize_L2(query_normalized)

            # Add vectors to index and search
            self.index.reset()
            self.index.add(vectors_matrix)
            scores, indices = self.index.search(
                query_normalized, min(top_k, len(stored_vectors))
            )

            return [
                (int(indices[0][i]), float(scores[0][i]))
                for i in range(len(indices[0]))
            ]
        except Exception as e:
            print(f"[VectorEngine] ‚ùå Search error: {e}")
            return []


# Global instances
_db_instance = None
_plugin_manager = None
_orchestrator = None
_vector_engine = None
_local_ai = None


def get_db_instance() -> PersistentForecastDB:
    """Get or create persistent database instance"""
    global _db_instance
    if _db_instance is None:
        _db_instance = PersistentForecastDB()
    return _db_instance


def get_plugin_manager() -> HotSwappablePluginManager:
    """Get or create plugin manager instance"""
    global _plugin_manager
    if _plugin_manager is None:
        _plugin_manager = HotSwappablePluginManager(get_db_instance())
    return _plugin_manager


def get_orchestrator() -> MultiAgentOrchestrator:
    """Get or create orchestrator instance"""
    global _orchestrator
    if _orchestrator is None:
        _orchestrator = MultiAgentOrchestrator(get_db_instance())
    return _orchestrator


def get_vector_engine() -> VectorEmbeddingEngine:
    """Get or create vector engine instance"""
    global _vector_engine
    if _vector_engine is None:
        _vector_engine = VectorEmbeddingEngine()
    return _vector_engine


def get_aetherra_local_ai():
    """Get or initialize Aetherra local AI engine"""
    global _local_ai
    if _local_ai is None and AETHERRA_NLP_AVAILABLE and LocalAIEngine is not None:
        try:
            _local_ai = LocalAIEngine()
            print("[GoalForecaster] ‚úÖ Aetherra Local AI initialized")
        except Exception as e:
            print(f"[GoalForecaster] ‚ùå Failed to initialize Local AI: {e}")
    return _local_ai


def analyze_goal_sentiment(goal: str) -> Dict[str, Any]:
    """Analyze sentiment and complexity of goal using enhanced AI and vector analysis"""
    # Try to use Aetherra's capabilities
    local_ai = get_aetherra_local_ai()
    if local_ai:
        try:
            # Use Aetherra's AI for sentiment analysis if available
            pass
        except Exception as e:
            print(f"[GoalForecaster] AI analysis error: {e}")

    # Enhanced vector-based analysis
    vector_engine = get_vector_engine()
    goal_embedding = None

    if vector_engine.model is not None:
        goal_embedding = vector_engine.encode_text(goal)
        if goal_embedding is not None:
            # Get similar historical forecasts for context
            db = get_db_instance()
            similar_forecasts = db.get_similar_forecasts(goal_embedding, limit=3)

            # Use similarity context for better analysis
            if similar_forecasts:
                avg_confidence = sum(f["confidence"] for f in similar_forecasts) / len(
                    similar_forecasts
                )
                print(
                    f"[GoalForecaster] Found {len(similar_forecasts)} similar historical goals"
                )

    # Enhanced sentiment analysis with vector context
    positive_words = [
        "improve",
        "enhance",
        "create",
        "build",
        "add",
        "upgrade",
        "optimize",
        "develop",
        "implement",
        "install",
        "configure",
        "setup",
        "enable",
    ]
    negative_words = [
        "delete",
        "remove",
        "destroy",
        "break",
        "shutdown",
        "format",
        "disable",
        "uninstall",
        "corrupt",
        "damage",
    ]
    neutral_words = [
        "check",
        "view",
        "list",
        "show",
        "display",
        "get",
        "analyze",
        "review",
        "monitor",
        "status",
    ]

    goal_lower = goal.lower()
    positive_score = sum(1 for word in positive_words if word in goal_lower)
    negative_score = sum(1 for word in negative_words if word in goal_lower)
    neutral_score = sum(1 for word in neutral_words if word in goal_lower)

    # Calculate sentiment with vector influence
    if negative_score > positive_score:
        sentiment = "negative"
        confidence = min(0.9, negative_score * 0.3 + 0.3)
    elif positive_score > negative_score:
        sentiment = "positive"
        confidence = min(0.9, positive_score * 0.3 + 0.3)
    else:
        sentiment = "neutral"
        confidence = 0.6

    return {
        "sentiment": sentiment,
        "confidence": confidence,
        "positive_score": positive_score,
        "negative_score": negative_score,
        "neutral_score": neutral_score,
        "vector_embedding": goal_embedding.tolist()
        if goal_embedding is not None
        else None,
        "semantic_analysis_available": vector_engine.model is not None,
    }


async def forecast_goal_async(
    goal: str, memory_system=None, plugin_index=None
) -> Dict[str, Any]:
    """
    Enhanced asynchronous goal forecasting with:
    - Persistent storage
    - Vector similarity analysis
    - Multi-agent orchestration
    - Real-time plugin capabilities
    """
    print(f"[GoalForecaster] üîÆ Forecasting goal: {goal}")

    # Initialize components
    db = get_db_instance()
    plugin_manager = get_plugin_manager()
    vector_engine = get_vector_engine()
    orchestrator = get_orchestrator()

    # Enhanced analysis with vector embeddings
    sentiment_analysis = analyze_goal_sentiment(goal)

    # Base risk assessment
    risk = "low"
    suggestions = []
    forecast = "Likely to succeed with current system capabilities."

    # Enhanced risk analysis
    if not goal or len(goal.strip()) < 10:
        risk = "high"
        forecast = "Goal is too vague or short for reliable forecasting."
        suggestions.append("Please provide more specific details about your goal.")
        suggestions.append("Consider breaking down complex goals into smaller steps.")
    elif (
        sentiment_analysis["sentiment"] == "negative"
        and sentiment_analysis["confidence"] > 0.7
    ):
        risk = "high"
        forecast = (
            "Goal involves potentially destructive actions - proceed with caution."
        )
        suggestions.append(
            "Consider backup procedures and safety measures before proceeding."
        )
        suggestions.append("Review system state and ensure rollback capabilities.")
    elif any(
        word in goal.lower()
        for word in ["delete", "remove", "shutdown", "format", "destroy"]
    ):
        risk = "high"
        forecast = "Goal may be destructive and requires careful validation."
        suggestions.append("Implement confirmation workflow before execution.")
        suggestions.append("Ensure proper backup and recovery procedures.")
    elif any(
        word in goal.lower()
        for word in ["install", "plugin", "extend", "add", "integrate"]
    ):
        risk = "medium"
        forecast = "Goal involves system modifications - validate compatibility."
        suggestions.append("Check plugin compatibility and dependencies.")
        suggestions.append("Consider testing in isolated environment first.")
    elif sentiment_analysis["sentiment"] == "positive":
        forecast = (
            "Goal shows positive intent and aligns well with system capabilities."
        )
        if sentiment_analysis["confidence"] > 0.7:
            suggestions.append("Goal appears well-structured for automated execution.")

    # Get goal embedding for vector analysis
    goal_embedding = None
    if sentiment_analysis.get("semantic_analysis_available"):
        vector_engine = get_vector_engine()
        goal_embedding = vector_engine.encode_text(goal)

    # Vector similarity insights
    if goal_embedding is not None:
        similar_forecasts = db.get_similar_forecasts(goal_embedding, limit=3)
        if similar_forecasts:
            avg_similarity = sum(f["similarity"] for f in similar_forecasts) / len(
                similar_forecasts
            )
            if avg_similarity > 0.8:
                suggestions.append(
                    f"Found {len(similar_forecasts)} similar historical goals with {avg_similarity:.1%} similarity."
                )
                suggestions.append(
                    "Consider reviewing historical outcomes for insights."
                )

    # Plugin capability assessment
    available_plugins = plugin_manager.get_available_plugins()
    relevant_plugins = []

    for plugin in available_plugins:
        if any(
            capability in goal.lower() for capability in plugin["capabilities"].keys()
        ):
            relevant_plugins.append(plugin["name"])

    if relevant_plugins:
        suggestions.append(f"Relevant plugins available: {', '.join(relevant_plugins)}")
        forecast += f" Enhanced by {len(relevant_plugins)} relevant plugins."

    # Calculate enhanced confidence score
    base_confidence = 0.75 if risk == "low" else (0.55 if risk == "medium" else 0.35)
    sentiment_modifier = (
        0.15
        if sentiment_analysis["sentiment"] == "positive"
        else (-0.15 if sentiment_analysis["sentiment"] == "negative" else 0)
    )
    length_modifier = min(0.1, len(goal.split()) * 0.015)
    plugin_modifier = min(0.1, len(relevant_plugins) * 0.03)

    # Vector similarity boost
    similarity_modifier = 0.0
    if goal_embedding is not None:
        similar_forecasts = db.get_similar_forecasts(goal_embedding, limit=1)
        if similar_forecasts and similar_forecasts[0]["similarity"] > 0.7:
            similarity_modifier = 0.05

    confidence = max(
        0.1,
        min(
            0.95,
            base_confidence
            + sentiment_modifier
            + length_modifier
            + plugin_modifier
            + similarity_modifier,
        ),
    )

    # Create enhanced forecast entry
    entry = {
        "type": "forecast",
        "goal": goal,
        "forecast_time": datetime.datetime.utcnow().isoformat(),
        "forecast": forecast,
        "risk": risk,
        "suggestions": suggestions,
        "confidence": confidence,
        "sentiment_analysis": sentiment_analysis,
        "relevant_plugins": relevant_plugins,
        "vector_embedding": goal_embedding,
        "nlp_enhanced": AETHERRA_NLP_AVAILABLE,
        "vector_enhanced": sentiment_analysis.get("semantic_analysis_available", False),
        "multi_agent_ready": True,
    }

    # Store in persistent database
    forecast_id = db.store_forecast(entry)
    entry["forecast_id"] = forecast_id

    # Optionally trigger multi-agent orchestration for complex goals
    if risk != "high" and len(goal.split()) > 5:
        try:
            orchestration_result = await orchestrator.orchestrate_goal_execution(
                goal, forecast_id
            )
            entry["orchestration"] = orchestration_result
            print("[GoalForecaster] ‚úÖ Multi-agent orchestration completed")
        except Exception as e:
            print(f"[GoalForecaster] [WARN] Orchestration error: {e}")
            entry["orchestration"] = {"success": False, "error": str(e)}

    print(
        f"[GoalForecaster] ‚úÖ Enhanced forecast completed with {confidence:.1%} confidence"
    )
    return entry


def forecast_goal(goal: str, memory_system=None, plugin_index=None) -> Dict[str, Any]:
    """
    Synchronous wrapper for enhanced goal forecasting
    Maintains backward compatibility while providing new features
    """
    try:
        # Run async forecasting in event loop
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(
            forecast_goal_async(goal, memory_system, plugin_index)
        )
        loop.close()
        return result
    except Exception as e:
        print(f"[GoalForecaster] ‚ùå Sync wrapper error: {e}")
        # Fallback to basic forecast
        return {
            "type": "forecast",
            "goal": goal,
            "forecast_time": datetime.datetime.utcnow().isoformat(),
            "forecast": "Basic forecast due to system limitations.",
            "risk": "medium",
            "suggestions": ["Upgrade system components for enhanced forecasting"],
            "confidence": 0.5,
            "sentiment_analysis": {"sentiment": "neutral", "confidence": 0.5},
            "error": str(e),
        }


# Hot-reload support
def reload_plugins():
    """Trigger hot reload of all plugins"""
    plugin_manager = get_plugin_manager()
    plugins = plugin_manager.get_available_plugins()

    results = []
    for plugin in plugins:
        success = plugin_manager.hot_reload_plugin(plugin["name"])
        results.append({"plugin": plugin["name"], "success": success})

    return results


# Database management
def get_forecast_history(limit: int = 10) -> List[Dict]:
    """Get recent forecast history from persistent storage"""
    db = get_db_instance()
    with db.lock:
        conn = sqlite3.connect(db.db_path)
        try:
            cursor = conn.execute(
                """
                SELECT goal, forecast, risk, confidence, created_at
                FROM forecasts
                ORDER BY created_at DESC
                LIMIT ?
            """,
                (limit,),
            )

            return [
                {
                    "goal": row[0],
                    "forecast": row[1],
                    "risk": row[2],
                    "confidence": row[3],
                    "created_at": row[4],
                }
                for row in cursor.fetchall()
            ]
        finally:
            conn.close()


def get_system_stats() -> Dict[str, Any]:
    """Get enhanced system statistics"""
    db = get_db_instance()
    plugin_manager = get_plugin_manager()
    vector_engine = get_vector_engine()

    with db.lock:
        conn = sqlite3.connect(db.db_path)
        try:
            # Forecast statistics
            cursor = conn.execute("SELECT COUNT(*) FROM forecasts")
            total_forecasts = cursor.fetchone()[0]

            cursor = conn.execute("SELECT AVG(confidence) FROM forecasts")
            avg_confidence = cursor.fetchone()[0] or 0.0

            # Agent task statistics
            cursor = conn.execute(
                "SELECT COUNT(*) FROM agent_tasks WHERE status = 'completed'"
            )
            completed_tasks = cursor.fetchone()[0]

            return {
                "total_forecasts": total_forecasts,
                "average_confidence": round(avg_confidence, 3),
                "completed_agent_tasks": completed_tasks,
                "available_plugins": len(plugin_manager.get_available_plugins()),
                "vector_embeddings_enabled": vector_engine.model is not None,
                "faiss_enabled": FAISS_AVAILABLE,
                "aetherra_nlp_enabled": AETHERRA_NLP_AVAILABLE,
                "database_path": db.db_path,
            }
        finally:
            conn.close()
    # Try to use Aetherra's capabilities
    local_ai = get_aetherra_local_ai()
    if local_ai:
        try:
            # Use Aetherra's AI for sentiment analysis if available
            # For now, we'll do basic analysis and prepare for future enhancement
            pass
        except Exception as e:
            print(f"[GoalForecaster] AI analysis error: {e}")


if __name__ == "__main__":
    import json

    # Test the enhanced goal forecaster
    test_goals = [
        "Install a new plugin for data analysis",
        "Delete all old log files from the system",
        "Optimize database performance and indexing",
        "Show current system status",
    ]

    print("üîÆ Enhanced Goal Forecaster Test Results")
    print("=" * 50)

    for goal in test_goals:
        print(f"\nüìã Goal: {goal}")
        result = forecast_goal(goal)
        print(f"üéØ Forecast: {result['forecast']}")
        print(f"[WARN] Risk: {result['risk']}")
        print(f"üìä Confidence: {result['confidence']:.1%}")
        print(f"üí° Suggestions: {len(result['suggestions'])} items")

    # Show system statistics
    print("\nüìà System Statistics:")
    stats = get_system_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")

    # Test hot reload
    print("\nüîÑ Testing hot reload...")
    reload_results = reload_plugins()
    for result in reload_results:
        status = "‚úÖ" if result["success"] else "‚ùå"
        print(f"  {status} {result['plugin']}")
